{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e2cffa3-36e9-4871-8767-ae6656f2a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet101V2, preprocess_input\n",
    "from keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.models import Model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8008798-5107-4f6f-8275-c936a2fc9c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters for training\n",
    "image_size = (224, 224)\n",
    "batch_size = 16\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34113527-344e-440b-952f-d0ea46f02711",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"E:/Farhan/DataSet/Train\"\n",
    "test_dataset_path = \"E:/Farhan/DataSet/Test\"\n",
    "validation_dataset_path = \"E:/Farhan/DataSet/Validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "123af5d0-ac6c-4995-b3c2-b7091bcc6a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of class names from the training dataset\n",
    "disease_categories = sorted(os.listdir(train_dataset_path))\n",
    "\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Create an image data generator\n",
    "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d17f1a6-9e59-477e-baa6-669e157f6c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3200 images belonging to 8 classes.\n",
      "Found 400 images belonging to 8 classes.\n",
      "Found 400 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create a generator for loading the training data\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    train_dataset_path,  # Path to the training dataset\n",
    "    target_size = image_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Create a generator for loading the testing data\n",
    "test_generator = data_generator.flow_from_directory(\n",
    "    test_dataset_path,  # Path to the testing dataset\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # No need to shuffle the testing data\n",
    ")\n",
    "\n",
    "# Create a generator for loading the validation data\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    validation_dataset_path,  # Path to the validation dataset folder\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # No need to shuffle the validation data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ac0b0a7-3f40-46a2-9ec6-65d16d455698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Load the trained model\n",
    "loaded_model = load_model('densenet121_model.h5')\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "61d22c59-2906-4bcf-9fb9-8fffd0c581cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image_path = 'E:/Farhan/DataSet/Train/Die Back/20211129_160425 (Custom).jpg'\n",
    "image = cv2.imread(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19a62bda-4600-4c19-8e81-b1b01fbdaaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.resize(image, (224, 224))  # resize to 224x224\n",
    "image = image / 255.0  # normalize pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5058eed5-d6b5-4d5f-9f8f-399cbd1bcfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "image_tensor = np.expand_dims(image, axis=0)  # add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "154a6aad-6b71-4f16-8720-0d54d90f0945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "Predicted class: Die Back\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the label encoder to the disease categories\n",
    "label_encoder.fit(disease_categories)\n",
    "\n",
    "# Load the image tensor (assuming it's a numpy array)\n",
    "image_tensor = np.expand_dims(image, axis=0)  # replace with your image tensor\n",
    "\n",
    "# Make predictions on the image tensor\n",
    "predictions = loaded_model.predict(image_tensor)\n",
    "\n",
    "# Get the predicted class index\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "\n",
    "# Get the class label from the label encoder\n",
    "predicted_class_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "\n",
    "# Print the predicted class label\n",
    "print(f\"Predicted class: {predicted_class_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a6a1e0-a10b-4dfd-bdef-d335fc35dacb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
